import numpy as np
from pyfftw.interfaces.numpy_fft import fft2, ifft2
from pyfftw import FFTW
from numba import jit
from datetime import datetime

def fast_cfft2(x, axes=(-1, -2)):
    if len(x.shape) == 2:
        return np.fft.fftshift(np.transpose(fft2(np.transpose(np.fft.ifftshift(x)))))
    elif len(x.shape) == 3:
        y = np.fft.ifftshift(x, axes=axes)
        y = fft2(y, axes=axes)
        y = np.fft.fftshift(y, axes=axes)
        return y


def cryo_epsds(image, samples_idx, max_d):
    """
    Estimate the 2D isotropic power spectrum of a given image using in each 
    image only the pixels given in samples_idx. Typically, samples_idx will 
    correspond to the pixles in the image that are outside a certain radius
    (where there is no particle). The power spectrum is estimated using the
    correlogram method.

    Parameters
    ----------
    image : numpy.ndarray
        Projection. Must be square and can have odd or even dimensions.
    samples_idx : tuple
        Pixel indices to use for autocorrelation estimation.
    max_d : int
        The autocorrelation is estimated for distances up to max_d. The value
        of max_d should be much less than the number of data samples, N. A 
        typical value in the literature is N/1, but this may result in a 
        spectrum that is too smooth.

    Returns
    -------
    p2 : numpy.ndarray
        2D power spectrum function. If each image is of size pxp, then P2 is 
        of size (2p-1)x(2p-1). P2 is always real.
    r : numpy.ndarray
        1D isotropic autocorrelation function.
    r2 : numpy.ndarray
        2D isotropic autocorrelation function.
    x : numpy.ndarray
        Distances at which the autocorrelction R was estimated.

    """
    p = image.shape[0]
    if max_d >= p:
        max_d = p - 1
    # Estimate the 1D isotropic autocorrelation function.
    r, x, _ = cryo_epsdr(image, samples_idx, max_d)
    
    # Use the 1D autocorrelation estimated above to populate an array of the 2D
    # isotropic autocorrelction.
    r2 = autocorr_2d(max_d, x, r, p)
    
    # Window the 2D autocorrelation and Fourier transform it to get the power
    # spectrum. Always use the Gaussian window, as it has positive Fourier
    # transform.     
    w = gwindow(p, max_d)
    p2 = np.fft.fftshift(fft2(np.fft.ifftshift(r2 * w))).real #maybe transpose
    
    # Normalize the power spectrum P2. The power spectrum is normalized such
    # that its energy is equal to the average energy of the noise samples used
    # to estimate it.
    e = np.sum(np.square(image[samples_idx] - np.mean(image[samples_idx])))
    mean_e = e / len(samples_idx[0])
    
    # Normalize p2 such that its mean energy is preserved and is equal to
    # mean_e. That way the mean energy does not go down if the number of 
    # pixels is artificially changed (say by upsampling, downsampling, or 
    # cropping). Note that p2 is already in units of energy, and so the total
    # energy is given by sum(p2) and not by norm(p2).
    p2 = (p2 / p2.sum()) * mean_e * p2.size
    
    # Due to the truncation of the Gaussian window, we get small negative
    # values in p2, so we ignore them.
    p2 = np.where(p2 < 0, 0, p2)
    return p2

def cryo_epsdr(image, samples_idx, max_d):
    """
    Estimate the 1D isotropic autocorrelation of an image. The samples to use
    are given in samples_idx. The correlation is computed up to a maximal
    distance of max_d.

    Parameters
    ----------
    image : numpy.ndarray
        square pxp image.
    samples_idx : tuple
        pixel indices to use for autocorrelation estimation.
    max_d : int
        Correlations are computed up to a maximal distance of max_d pixels.
        Default p-1.

    Returns
    -------
    r : numpy.ndarray
        1D vector with samples of the isotropic autocorrelation function.
    x : numpy.ndarray
        Distaces at which the samples of the autocorrelation function are
        given. A vector of the same length as R.
    cnt : numpy.ndarray
        Number of autocorrelation samples available for each distance.

    """
    p = image.shape[0]
    
    # Generate all possible squared distances. For a vertical shift i and 
    # horizontal shift j, dists(i,j) contains the corresponding isotropic 
    # correlation distance i^2+j^2. dsquare is then the set of all possible 
    # squared distances, that is, all distances that can be generated by 
    # integer steps in the horizontal and vertical directions.
    i = np.array([[x for x in range(max_d + 1)] for x in range(max_d + 1)])
    dists = i ** 2 + i.transpose() ** 2
    dsquare = np.sort(np.unique(dists[np.where(dists <= max_d ** 2)]))
    x = dsquare ** 0.5 # Distances at which the correlations are computed.
    
    # Create a distance map whose value at the index (i,j) is the index in the
    # array dsquare whose value is i^2+j^2. Pairs (i,j) that correspond to
    # distances that are larger than max_d are indicated by (-1).   
    dist_map = distmap(max_d, dsquare, dists.shape)
    valid_dists = np.where(dist_map != -1)

    # Compute the number of terms in the expression sum_{j}x(j)x(j+d) for each
    # distance d. As the correlation is two-dimensioanl, we compute for each
    # sum of the form  R(k1,k2)=sum_{i,j} X_{i,j} X_{i+k1,j+k2}, how many 
    # summands are in the in it for each (k1,k2). This is done by setting the
    # participating image samples to 1 and computing autocorrelation again.
    mask = np.zeros((p, p))
    mask[samples_idx] = 1
    tmp = np.zeros((2 * p + 1, 2 * p + 1))
    tmp[:p, :p] = mask
    ftmp = fft2(tmp)
    c = ifft2(ftmp * np.conj(ftmp))
    c = c[:max_d + 1, :max_d + 1]
    c = np.round(c.real).astype('int') 

    r = np.zeros(len(dsquare)) # r(i) is the value of the ACF at distance x(i)
    
    # Compute non-periodic autocorrelation of masked image with itself (mask
    # all pixels that are not used to autocorrelation estimation).
    input_fft2 = np.zeros((2 * p + 1, 2 * p + 1), dtype='complex128')
    output_fft2 = np.zeros((2 * p + 1, 2 * p + 1), dtype='complex128')
    input_ifft2 = np.zeros((2 * p + 1, 2 * p + 1), dtype='complex128')
    output_ifft2 = np.zeros((2 * p + 1, 2 * p + 1), dtype='complex128')
    flags = ('FFTW_MEASURE', 'FFTW_UNALIGNED')
    a_fft2 = FFTW(input_fft2, output_fft2, axes=(0, 1), direction='FFTW_FORWARD', flags=flags)
    a_ifft2 = FFTW(input_ifft2, output_ifft2, axes=(0, 1), direction='FFTW_BACKWARD', flags=flags)
    sum_c = c
    
    input_fft2[samples_idx] = image[samples_idx]
    a_fft2()
    np.multiply(output_fft2, np.conj(output_fft2), out=input_ifft2)
    a_ifft2()
    sum_s = output_ifft2
    
    # Accumulate all autocorrelation values R(k1,k2) such that k1^2+k2^2=const 
    # (all autocorrelations of a certain distance).
    # corrs(i) contains the sum of all products of the form x(j)x(j+d), where
    # d=sqrt(dsquare(i)).
    # corr_count is the number of pairs x(j)x(j+d) for each d.
    corr_count, corrs = accumelate_corrs(len(dsquare), valid_dists, dist_map, sum_c, sum_s)

    # Remove zero correlation sums (distances for which we had no samples at 
    # that distance)
    idx = np.where(corr_count != 0)[0]
    r[idx] += corrs[idx] / corr_count[idx]
    cnt = corr_count[idx]
    idx = np.where(corr_count == 0)[0]
    r[idx] = 0
    x[idx] = 0
    return r, x, cnt


@jit(nopython=True)
def bsearch(x, lower_bound, upper_bound):
    """
    Binary search in a sorted vector.
    
    Binary O(log2(N)) search of the range of indices of all elements of x 
    between LowerBound and UpperBound. If no elements between LowerBound and
    Upperbound are found, the returned lower_index and upper_index are empty.
    The array x is assumed to be sorted from low to high, and is NOT verified
    for such sorting. 
    Based on code from 
    http://stackoverflow.com/questions/20166847/faster-version-of-find-for-sorted-vectors-matlab

    Parameters
    ----------
    x : numpy.ndarray
        A vector of sorted values from low to high.
    lower_bound : float
        Lower boundary on the values of x in the search.
    upper_bound : flo
        Upper boundary on the values of x in the search.

    Returns
    -------
    lower_idx: int
        The smallest index such that LowerBound<=x(index)<=UpperBound.
    upper_idx: int
        The largest index such that LowerBound<=x(index)<=UpperBound.

    """
    if lower_bound > x[-1] or upper_bound < x[0] or upper_bound < lower_bound:
        return None, None
    lower_idx_a = 1
    lower_idx_b = len(x)
    upper_idx_a = 1
    upper_idx_b = len(x)

    while lower_idx_a + 1 < lower_idx_b or upper_idx_a + 1 < upper_idx_b:
        lw = int(np.floor((lower_idx_a + lower_idx_b) / 2))
        if x[lw - 1] >= lower_bound:
            lower_idx_b = lw
        else:
            lower_idx_a = lw
            if upper_idx_a < lw < upper_idx_b:
                upper_idx_a = lw

        up = int(np.ceil((upper_idx_a + upper_idx_b) / 2))
        if x[up - 1] <= upper_bound:
            upper_idx_a = up
        else:
            upper_idx_b = up
            if lower_idx_a < up < lower_idx_b:
                lower_idx_b = up

    if x[lower_idx_a - 1] >= lower_bound:
        lower_idx = lower_idx_a
    else:
        lower_idx = lower_idx_b
    if x[upper_idx_b - 1] <= upper_bound:
        upper_idx = upper_idx_b
    else:
        upper_idx = upper_idx_a

    if upper_idx < lower_idx:
        return None, None

    return lower_idx, upper_idx

@jit(nopython=True)
def gwindow(p, max_d):
    """
    Create 2D Gaussian window for spectral estimation. Return a (2p-1)x(2p-1) 
    Gaussian window to be used for 2D power spectrum estimation. 

    Parameters
    ----------
    p : int
        Size of the returned mask.
    max_d : int
        Width of the Gaussian.

    Returns
    -------
    w : numpy.ndarray
        (2p-1)x(2p-1) array..

    """
    l = 2 * p - 1
    y = np.array([[x for x in range(l)] for x in range(l)])
    x = y - p + 1
    alpha = float(3)
    # Reciprocal of the standard deviation of the Gaussian window. 1/alpha is
    # the width of the Fourier transform of the window.See Harris 78 for more
    # details. 
    w = np.exp(-alpha * (x ** 2 + x.transpose() ** 2) / (2 * max_d ** 2))
    return w

@jit(nopython=True)
def accumelate_corrs(dsquare_len, valid_dists, dist_map, sum_c, sum_s):
    corr_count = np.zeros(dsquare_len)
    corrs = np.zeros(dsquare_len)
    for curr_dist in zip(valid_dists[0], valid_dists[1]):
        dmidx = dist_map[curr_dist]
        corrs[dmidx] += sum_s[curr_dist].real
        corr_count[dmidx] += sum_c[curr_dist]
    return corr_count, corrs

@jit(nopython=True)        
def autocorr_2d(max_d, x, r, p):
    """
    Use the 1D autocorrelation r, x to populate an array r2 of the 2D
    isotropic autocorrelation.

    Parameters
    ----------
    max_d : int
        The 1D autocorrelations were computed up to a maximal distance of 
        max_d pixels.
    x : numpy.ndarray
        Distaces at which the samples of the autocorrelation function are
        given. A vector of the same length as r.
    r : numpy.ndarray
        1D vector with samples of the isotropic autocorrelation function.
    p : int
        The dimension of the square image that is being processed.

    Returns
    -------
    r2 : numpy.ndarray
        2D isotropic autocorrelation.

    """
    dsquare = x ** 2
    r2 = np.zeros((int(2 * p - 1), int(2 * p - 1)), dtype=np.float64)
    for i in range(-max_d, max_d + 1):
        for j in range(-max_d, max_d + 1):
            d = i ** 2 + j ** 2
            if d <= max_d ** 2:
                idx, _ = bsearch(dsquare, d * (1 - 1e-13), d * (1 + 1e-13))
                r2[i + p - 1, j + p - 1] = r[int(idx) - 1]        
    return r2

@jit(nopython=True)
def distmap(max_d, dsquare, dists_shape):
    """
    Create a distance map whose value at the index (i,j) is the index in the
    array dsquare whose value is i^2+j^2. Pairs (i,j) that correspond to
    distances that are larger than max_d are indicated by (-1).  
    """
    dist_map = np.zeros(dists_shape)
    for i in range(max_d + 1):
        for j in range(max_d + 1):
            d = i ** 2 + j ** 2
            if d <= max_d ** 2:
                idx, _ = bsearch(dsquare, d - 1e-13, d + 1e-13)
                dist_map[i, j] = idx
    dist_map = dist_map.astype(np.int32) - 1
    return dist_map

patch_size = 79

block = np.load("/home/dalitcohen/Documents/tmp.npy")
start = datetime.now()
for i in range(1000):
    psd_block1 = cryo_epsds(block,
                       np.where(np.zeros((int(patch_size), int(patch_size))) == 0),
                       int(np.floor(0.3 * patch_size)))
    
print(datetime.now()-start)
print(psd_block1[0])